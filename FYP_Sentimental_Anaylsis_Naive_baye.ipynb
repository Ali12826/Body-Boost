{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.pipeline import make_pipeline\n"
      ],
      "metadata": {
        "id": "fQnU5as87Ctt"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Important libraries\n",
        "**import pandas as pd:** Imports the pandas library, commonly used for data manipulation and analysis.  \n",
        "\n",
        "**from sklearn.feature_extraction.text import CountVectorizer:** Importing CountVectorizer for converting text data into a bag-of-words representation.\n",
        "\n",
        "**from sklearn.naive_bayes import MultinomialNB:** Importing Multinomial Naive Bayes classifier, suitable for text classification tasks.\n",
        "\n",
        "**from sklearn.metrics import accuracy_score, classification_report:** Importing evaluation metrics like accuracy score and classification report.\n",
        "\n",
        "**from sklearn.pipeline import make_pipeline:** Importing a function to create a pipeline for simplifying the workflow.\n",
        "\n"
      ],
      "metadata": {
        "id": "ly3v1MBL7J-c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv('/content/drive/MyDrive/colab/training.csv')\n",
        "validation_df = pd.read_csv('/content/drive/MyDrive/colab/validation.csv')\n",
        "test_df = pd.read_csv('/content/drive/MyDrive/colab/test.csv')\n",
        "train_data, train_labels = train_df['text'], train_df['label']\n",
        "validation_data, validation_labels = validation_df['text'], validation_df['label']\n",
        "test_data, test_labels = test_df['text'], test_df['label']\n",
        "train_df = train_df.dropna() #Droping rows with missing values\n",
        "train_df = train_df.drop_duplicates(subset=['text', 'label']) # Removeing any duplicates based on 'text' and 'label'"
      ],
      "metadata": {
        "id": "Go8RqNee96Ku"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset Pre-Processing\n",
        "**Loading Datasets:** Loads training, validation, and test datasets from CSV files located at specific file paths using pandas read_csv function\n",
        "**Extracting Features and Labels:** Extracts the 'text' column as features and the 'label' column as labels from each dataset, creating separate data and label sets for training, validation, and test datasets.                          \n",
        "**Handling Missing Values:** Removes rows with missing values (NaN) from the training dataset using the dropna function.\n",
        "**Handling Duplicate Values:** Removes duplicate rows based on both 'text' and 'label' columns from the training dataset using the drop_duplicates function."
      ],
      "metadata": {
        "id": "js1d5MnX2HUg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = make_pipeline(CountVectorizer(), MultinomialNB())\n",
        "model.fit(train_data, train_labels)\n",
        "validation_predictions = model.predict(validation_data)\n",
        "validation_accuracy = accuracy_score(validation_labels, validation_predictions)# Evaluating the model on the validation set\n",
        "print(f\"Validation Accuracy: {validation_accuracy:.2f}\")\n",
        "print(\"Validation Classification Report:\")\n",
        "print(classification_report(validation_labels, validation_predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1EW71Sb6_-E5",
        "outputId": "4e0c070f-3a31-4bf0-a09a-2799be0a5286"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.76\n",
            "Validation Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.94      0.80       550\n",
            "           1       0.76      0.95      0.84       704\n",
            "           2       0.90      0.25      0.39       178\n",
            "           3       0.93      0.61      0.73       275\n",
            "           4       0.89      0.55      0.68       212\n",
            "           5       1.00      0.09      0.16        81\n",
            "\n",
            "    accuracy                           0.76      2000\n",
            "   macro avg       0.86      0.57      0.60      2000\n",
            "weighted avg       0.80      0.76      0.73      2000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the model & Validation Acuracy\n",
        "**Create Pipeline:** involves chaining together a sequence of data processing steps and a machine learning model into a single, unified workflow.              \n",
        "**Train the Model:** Fits the model to the training data (train_data and train_labels) using the fit method, training the model to recognize patterns in the text.\n",
        "**Make Predictions on Validation Set:** Applies the trained model to the validation dataset (validation_data) to make predictions on the text data using the predict method.\n",
        "**Evaluate Model Performance on Validation Set:** Computes the accuracy and generates a classification report by comparing the model's predictions (validation_predictions) with the true labels (validation_labels)."
      ],
      "metadata": {
        "id": "VcJ_aL8-3FOt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_predictions = model.predict(test_data)\n",
        "test_accuracy = accuracy_score(test_labels, test_predictions) # Evaluate the model on the test set\n",
        "print(f\"Test Accuracy: {test_accuracy:.2f}\")\n",
        "print(\"Test Classification Report:\")\n",
        "print(classification_report(test_labels, test_predictions))\n",
        "\n",
        "def predict_sentiment(tweet):#trained model to predict the sentiment of new tweets\n",
        "\n",
        "    result = model.predict([tweet])\n",
        "    return result[0]\n",
        "new_tweet = \"We have won the match\"\n",
        "predicted_sentiment = predict_sentiment(new_tweet)\n",
        "print(f\"Predicted sentiment: {predicted_sentiment}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDU8Tznd_OZy",
        "outputId": "022fa4f4-4074-44d7-ee9e-ff6ef502b9e4"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.77\n",
            "Test Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.94      0.83       581\n",
            "           1       0.74      0.97      0.84       695\n",
            "           2       0.95      0.23      0.37       159\n",
            "           3       0.92      0.57      0.70       275\n",
            "           4       0.82      0.53      0.64       224\n",
            "           5       0.00      0.00      0.00        66\n",
            "\n",
            "    accuracy                           0.77      2000\n",
            "   macro avg       0.69      0.54      0.56      2000\n",
            "weighted avg       0.77      0.77      0.73      2000\n",
            "\n",
            "Predicted sentiment: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predicting sentiment of New Tweet & Testing data Accuracy\n",
        "**Make Predictions on Test Set:** The trained model (model) is used to predict labels for the test dataset (test_data) using the predict method, generating test_predictions.                   \n",
        "**Evaluate Model on Test Set:** The accuracy of the model on the test set is calculated by comparing the predicted labels (test_predictions) with the true labels (test_labels), and the result is stored in test_accuracy.    \n",
        "**Predict Sentiment of New Tweet:** A function predict_sentiment(tweet) is defined to predict the sentiment of a new tweet using the trained model."
      ],
      "metadata": {
        "id": "2G7pPYuI9eGR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "emotion_labels = {0: 'sadness', 1: 'joy', 2: 'love', 3: 'anger', 4: 'fear'}\n",
        "\n",
        "def predict_sentiment(tweet):\n",
        "    result = model.predict([tweet])\n",
        "    sentiment_label = emotion_labels[result[0]]\n",
        "    return sentiment_label\n",
        "\n",
        "user_input_tweet = input(\"Enter a tweet: \")\n",
        "predicted_sentiment = predict_sentiment(user_input_tweet)\n",
        "print(f\"Predicted sentiment for the entered tweet: {predicted_sentiment}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgaZkhdVR90F",
        "outputId": "f17942a2-1c7b-42f2-c55b-46548e19014d"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a tweet: My Grand Father died Yesterday\n",
            "Predicted sentiment for the entered tweet: sadness\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Conversion of Emotion Labels\n",
        "**Emotion Label Mapping:** In this we are mapping emotion_labels from numeric sentiment labels to human-readable emotions: {0: 'sadness', 1: 'joy', 2: 'love', 3: 'anger', 4: 'fear'}.   \n",
        "**Sentiment Prediction Function:** The predict_sentiment function takes a tweet as input, predicts its sentiment using a trained model (model)."
      ],
      "metadata": {
        "id": "ONJvv_D2TlHY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from scipy.special import softmax\n",
        "\n",
        "tweet = ' My Grand Father died yesterday ðŸ˜’ !  '\n",
        "\n",
        "tweet_words = []\n",
        "\n",
        "for word in tweet.split(' '):\n",
        "    if word.startswith('@') and len(word) > 1:\n",
        "        word = '@user'\n",
        "    elif word.startswith('http'):\n",
        "        word = \"http\"\n",
        "    tweet_words.append(word)\n",
        "\n",
        "tweet_proc = \" \".join(tweet_words)\n",
        "\n",
        "#  model\n",
        "roberta = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
        "model = AutoModelForSequenceClassification.from_pretrained(roberta)\n",
        "tokenizer = AutoTokenizer.from_pretrained(roberta)\n",
        "\n",
        "labels = ['Negative', 'Neutral', 'Positive']\n",
        "\n",
        "# sentiment analysis\n",
        "encoded_tweet = tokenizer(tweet_proc, return_tensors='pt')\n",
        "output = model(**encoded_tweet)\n",
        "\n",
        "scores = output.logits[0].detach().numpy()\n",
        "softmax_scores = softmax(scores)\n",
        "\n",
        "for i in range(len(labels)):\n",
        "    sentiment = labels[i]\n",
        "    percentage = softmax_scores[i] * 100\n",
        "    print(f\"{sentiment} Percentage: {percentage:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZ3ryghJ0QK4",
        "outputId": "deb11f09-3df1-4d6b-9ed4-5adeee56aec1"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:72: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Negative Percentage: 95.42%\n",
            "Neutral Percentage: 4.07%\n",
            "Positive Percentage: 0.51%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pr-Trained model Roberto Facebook AI\n",
        "**Model used:**  RoBERTa-base model  \n",
        "**Data set:** This model is trained on 154M tweets    \n",
        "**Last Release Date:** December 2022  \n",
        "**Tasks:**  Sentiment Analysis,Offensive Language Identification,Emoji Prediction,Irony Detection.    \n",
        "**F1 (micro):** 0.7169   \n",
        "**F1 (macro):** 0.5464\n"
      ],
      "metadata": {
        "id": "ld9yUpkxCSWA"
      }
    }
  ]
}